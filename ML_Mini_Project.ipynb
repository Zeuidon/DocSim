{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARCvQqmJkGPM",
        "outputId": "c31c3471-a4c6-4ffa-8ad7-a8df7f519be1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: constants in /home/zeuidon/.local/lib/python3.10/site-packages (0.6.0)\n",
            "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Jg7TlveX2T",
        "outputId": "d33bd735-f719-45d4-e9ac-bfd59b06c0ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: PyPDF2<3.0 in /home/zeuidon/.local/lib/python3.10/site-packages (2.12.1)\n",
            "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install 'PyPDF2<3.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N2E8XuOg2bt",
        "outputId": "cfba53c0-b3bf-4aad-9d54-2d7643052875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: transformers in /home/zeuidon/.local/lib/python3.10/site-packages (4.30.0)\n",
            "Requirement already satisfied: filelock in /home/zeuidon/.local/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/zeuidon/.local/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/zeuidon/.local/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/zeuidon/.local/lib/python3.10/site-packages (from transformers) (2023.8.8)\n",
            "Requirement already satisfied: requests in /home/zeuidon/.local/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/zeuidon/.local/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/zeuidon/.local/lib/python3.10/site-packages (from transformers) (0.3.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/zeuidon/.local/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /home/zeuidon/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/zeuidon/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/zeuidon/.local/lib/python3.10/site-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (3.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->transformers) (1.26.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2020.6.20)\n",
            "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hksrOvrgsjxz",
        "outputId": "7b2f783f-119a-4bde-97b0-62e12b10d1c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /home/zeuidon/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
            "/home/zeuidon/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n",
            "CUDA SETUP: Loading binary /home/zeuidon/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/zeuidon/.local/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
            "[nltk_data] Downloading package punkt to /home/zeuidon/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/zeuidon/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /home/zeuidon/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pickle\n",
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import constants as const\n",
        "import PyPDF2\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "nltk.download(['punkt', 'stopwords', 'wordnet'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdP9zp5eZnEL",
        "outputId": "314f1941-92bb-4604-f438-e3351e387ddb"
      },
      "outputs": [],
      "source": [
        "def tfidf_similarity(tokenized_text1, tokenized_text2):\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform([tokenized_text1, tokenized_text2])\n",
        "\n",
        "    # Similarity Measurement\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
        "\n",
        "    return cosine_sim[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iUI3NxpzgjRa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "model_name = \"bert-base-uncased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertModel.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "R8tiWi0slVmA"
      },
      "outputs": [],
      "source": [
        "def compute_bert_embeddings(sentence, model, tokenizer):\n",
        "    input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
        "    input_ids = torch.tensor(input_ids).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        output = model(input_ids)\n",
        "    return output.last_hidden_state.mean(dim=1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2CnzW6i-lWQQ"
      },
      "outputs": [],
      "source": [
        "def combine_embeddings(long_text):\n",
        "  max_segment_length = 512  # Maximum segment length allowed by BERT\n",
        "  segments = [long_text[i:i + max_segment_length] for i in range(0, len(long_text), max_segment_length)]\n",
        "\n",
        "  # Initialize an empty tensor for aggregated embeddings\n",
        "  aggregated_embeddings = torch.zeros((1, 768))  # Ensure the size matches BERT's embedding size (e.g., 768)\n",
        "\n",
        "  # Process each segment separately and aggregate embeddings\n",
        "  for segment in segments:\n",
        "      encoded_input = tokenizer(segment, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "      with torch.no_grad():\n",
        "          output = model(**encoded_input)\n",
        "      segment_embedding = output.last_hidden_state.mean(dim=1)  # Mean pooling over tokens\n",
        "      aggregated_embeddings += segment_embedding\n",
        "  return aggregated_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnv-KSQ5lYDa",
        "outputId": "78ef6d65-1f0a-4651-f21b-23692e6510e9"
      },
      "outputs": [],
      "source": [
        "def bert_similarity(tokenized_text1, tokenized_text2) :\n",
        "    embeddings1 = combine_embeddings(tokenized_text1)\n",
        "    embeddings2 = combine_embeddings(tokenized_text2)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    return cosine_similarity(embeddings1, embeddings2)[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: fastapi in /home/zeuidon/.local/lib/python3.10/site-packages (0.110.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /home/zeuidon/.local/lib/python3.10/site-packages (from fastapi) (1.10.12)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /home/zeuidon/.local/lib/python3.10/site-packages (from fastapi) (0.37.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/zeuidon/.local/lib/python3.10/site-packages (from fastapi) (4.11.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /home/zeuidon/.local/lib/python3.10/site-packages (from starlette<0.38.0,>=0.37.2->fastapi) (3.7.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/lib/python3/dist-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (3.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /home/zeuidon/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /home/zeuidon/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi) (1.1.3)\n",
            "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install fastapi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pydantic in /home/zeuidon/.local/lib/python3.10/site-packages (1.10.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /home/zeuidon/.local/lib/python3.10/site-packages (from pydantic) (4.11.0)\n",
            "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [18564]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     127.0.0.1:56894 - \"POST /in HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class Item(BaseModel):\n",
        "    t1: str\n",
        "    t2: str\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "@app.post(\"/in\")\n",
        "def create(item: Item):\n",
        "    dt = item.dict()\n",
        "    text1 = dt['t1']\n",
        "    text2 = dt['t2']\n",
        "    b = str(bert_similarity(text1, text2))\n",
        "    t =  str(tfidf_similarity(text1, text2))\n",
        "    return {\n",
        "        \"Bert similarity\": b, \n",
        "        \"Tfidf similarity\": t\n",
        "    }\n",
        "\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    nest_asyncio.apply()\n",
        "    uvicorn.run(app)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
